{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b778de08-424f-45bf-9ac4-c626efc1133f",
   "metadata": {},
   "source": [
    "# Keep your code clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ffc7b-d964-4057-9da4-b834390a5a0b",
   "metadata": {},
   "source": [
    "Jupyter notebooks often start as exploration and experimentation by an indivudal data scientist. The code is not mean to be shared and certainly not to run beyond the early days of a project. However, snippets of code from Jupyter notebooks often make their way to production servers, where they run for months, possibly years.\n",
    "\n",
    "Software engineers have been developing best practices around making code more readable. Although the basic principles are shared, languages also develop their own culsture and aesthetics. For example, in Java variables are namde in camel case, such as `studentAge`, `dateOfBirth`, C# uses pascal case capitalizes the first letter, such as `StudentAge`, `DateOfBirth`, lisp uses kebab-case as `student-age`, `date-of-birth` and our favorite language, Python uses snake-case: `student_age`, `date_of_birth` for variables. \n",
    "\n",
    "Languages often use a different convention for class names. Python pascal case: `TextClassifier`, `ConsoleLogger`.\n",
    "\n",
    "**NOTE**: The examples below are guidelines. There are often good reasons to deviate from best practices. Do not feel beholden to the rules below. As with any culture, some norms are barely enforced and some norms will cast you out.\n",
    "\n",
    "### Names should be meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911d94d-7053-4b55-9f6f-8a68049714bd",
   "metadata": {},
   "source": [
    "**Variables**\n",
    "\n",
    "```python\n",
    "# Bad\n",
    "x = np.mean(data)\n",
    "df2 = process(df1)\n",
    "lst = [1, 2, 3]\n",
    "\n",
    "# Good\n",
    "average_score = np.mean(student_scores)\n",
    "processed_dataframe = process(raw_dataframe)\n",
    "prime_numbers = [1, 2, 3]\n",
    "```\n",
    "\n",
    "Notice that we can make this look even better (and easier to ready) by aligning the equals signs:\n",
    "```python\n",
    "average_score       = np.mean(student_scores)\n",
    "processed_dataframe = process(raw_dataframe)\n",
    "prime_numbers       = [1, 2, 3]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8ea10-a2d2-48ae-98a2-8a0cdda4df8b",
   "metadata": {},
   "source": [
    "**Functions**\n",
    "\n",
    "```python\n",
    "# Bad\n",
    "def proc_data():\n",
    "    pass\n",
    "\n",
    "# Good\n",
    "def preprocess_text_data(raw_text):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f810c-0427-4fc4-99ee-e21ca515b520",
   "metadata": {},
   "source": [
    "**Classes**\n",
    "\n",
    "```python\n",
    "# Bad\n",
    "class Mdl:\n",
    "    pass\n",
    "\n",
    "# Good\n",
    "class TextClassifierModel:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d1566-8eb9-43bb-85d1-d18c6ee97bf2",
   "metadata": {},
   "source": [
    "### Imports should be organized by functionality and source\n",
    "\n",
    "```python\n",
    "# Standard library\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Local\n",
    "from src.data.loading import load_dataset\n",
    "from src.features.engineering import create_features\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491edb6-e0e0-4a7a-8de3-413ae3cb9ff8",
   "metadata": {},
   "source": [
    "### Functions should be documented using docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb1d58a1-d93b-460f-b071-ec56f465a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_importance(\n",
    "    model,\n",
    "    feature_name\n",
    ") :\n",
    "    \"\"\"Calculate feature importance scores from a trained random forest model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained random forest classifier\n",
    "        feature_names: List of feature names corresponding to model features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping feature names to their importance scores\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If length of feature_names doesn't match model features\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cbdad6-c12e-4740-b6a7-42ae468e6839",
   "metadata": {},
   "source": [
    "Notice that this docstring now allows us to ask for help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25df519e-5872-4e36-9ed3-d8e2fe626a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function calculate_feature_importance in module __main__:\n",
      "\n",
      "calculate_feature_importance(model, feature_name)\n",
      "    Calculate feature importance scores from a trained random forest model.\n",
      "    \n",
      "    Args:\n",
      "        model: Trained random forest classifier\n",
      "        feature_names: List of feature names corresponding to model features\n",
      "        \n",
      "    Returns:\n",
      "        Dictionary mapping feature names to their importance scores\n",
      "        \n",
      "    Raises:\n",
      "        ValueError: If length of feature_names doesn't match model features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(calculate_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05cb4a-6725-48e5-b846-6c439555032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_feature_importance() #place cursor inside parenthesis and press SHIFT+TAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ea68a-0fa6-4121-ab8c-9e39a2a8042f",
   "metadata": {},
   "source": [
    "**Explain the code appropriately**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435dfc47-76de-45ea-9200-5688afbcedc8",
   "metadata": {},
   "source": [
    "Bad: Explains what the code does\n",
    "\n",
    "```python\n",
    "# Loop through the dataframe\n",
    "for idx, row in df.iterrows():\n",
    "    processed.append(row)\n",
    "```\n",
    "\n",
    "Good: Explains why the code is needed\n",
    "\n",
    "```python\n",
    "# Handle missing values before modeling to prevent training errors\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de6a2a-be19-4ed4-85c4-2e4e4f5a8a0f",
   "metadata": {},
   "source": [
    "### Functions should not be too large and do one thing\n",
    "\n",
    "```python\n",
    "# Bad\n",
    "def process_and_train_and_evaluate():\n",
    "    # Load data\n",
    "    # Load data...\n",
    "    # Load data...\n",
    "    # Process data......\n",
    "    # Process data..\n",
    "    # Process data...\n",
    "    # Train model\n",
    "    # Evaluate model\n",
    "    # Save results\n",
    "    pass\n",
    "\n",
    "# Good\n",
    "def load_data(filepath: str) -> pd.DataFrame:\n",
    "    pass\n",
    "\n",
    "def preprocess_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass\n",
    "\n",
    "def train_model(X: np.ndarray, y: np.ndarray) -> sklearn.base.BaseEstimator:\n",
    "    pass\n",
    "\n",
    "def evaluate_model(model: sklearn.base.BaseEstimator, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, float]:\n",
    "    pass\n",
    "\n",
    "def process_and_train_and_evaluate():\n",
    "    load_data()\n",
    "    preprocess_features()\n",
    "    train_model()\n",
    "    evaluate_model()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f59b1-7c3d-4445-bc09-18e97e84356e",
   "metadata": {},
   "source": [
    "**NOTE** We will learn more about these conventions, including additional ones, like adding type annotations, throughout this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234628e2-1593-4d53-be8c-22972d796f42",
   "metadata": {},
   "source": [
    "### Automated tools\n",
    "There are a large number of tools which can help you format and check your code. Two tools, important for this lecture are: `pylint` and `black`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31540ad5-eb92-4b69-bb10-8ae3caad501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting messy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile messy.py\n",
    "# messy.py\n",
    "import pandas as pd,numpy as np\n",
    "from typing import List,Dict,Any\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class dataProcessor:\n",
    "    def __init__(self,input_file:str,    output_file:str='processed.csv'):\n",
    "        self.input=input_file\n",
    "        self.output_file=output_file \n",
    "        self.data=None\n",
    "    \n",
    "    def Load_data(self):\n",
    "        \"\"\"loads data from csv file\"\"\"\n",
    "        self.data=pd.read_csv(self.input)\n",
    "        return self.data\n",
    "    \n",
    "    def process(self,columns_to_process:List[str]=[],aggfunc:str='mean')->pd.DataFrame:\n",
    "        if len(columns_to_process)==0: return self.data\n",
    "        processed_data={}\n",
    "        for col in columns_to_process:\n",
    "         if col in self.data.columns:\n",
    "          processed_data[col]=getattr(self.data[col],aggfunc)()\n",
    "         else:\n",
    "            print(f\"Warning: Column {col} not found\")\n",
    "        return pd.DataFrame(processed_data,index=[0])\n",
    "\n",
    "    def visualize_data(self,   column:str,   PlotType:str='bar'   )->None:\n",
    "        if self.data is None:raise ValueError('No data loaded')\n",
    "        plt.figure(figsize=(10,     5))\n",
    "        if PlotType=='bar':\n",
    "            self.data[column].value_counts().plot(kind='bar')\n",
    "        elif     PlotType=='hist':\n",
    "            self.data[column].hist()\n",
    "        plt.title(f'Visualization of {column}')\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    processor=dataProcessor('data.csv')\n",
    "    df = processor.Load_data()\n",
    "    processed=processor.process(['age','salary'],aggfunc='mean')\n",
    "    processor.visualize_data('age','hist')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06135a-0afd-4ca9-b5e8-5ca2256c5fdc",
   "metadata": {},
   "source": [
    "Turn on line numbers from View->Show Line Numbers to match output from the following programs to the program above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6750b10-39e8-45ac-bb4f-f83f58d07f26",
   "metadata": {},
   "source": [
    "You may have to install these tools:\n",
    "\n",
    "`pip install pylint black`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c334907-d30c-4ccb-bd3e-3c71b5a16975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Module messy\n",
      "messy.py:11:0: C0303: Trailing whitespace (trailing-whitespace)\n",
      "messy.py:16:0: C0303: Trailing whitespace (trailing-whitespace)\n",
      "messy.py:21:0: W0311: Bad indentation. Found 9 spaces, expected 12 (bad-indentation)\n",
      "messy.py:22:0: W0311: Bad indentation. Found 10 spaces, expected 16 (bad-indentation)\n",
      "messy.py:23:0: W0311: Bad indentation. Found 9 spaces, expected 12 (bad-indentation)\n",
      "messy.py:24:0: W0311: Bad indentation. Found 12 spaces, expected 16 (bad-indentation)\n",
      "messy.py:1:0: C0114: Missing module docstring (missing-module-docstring)\n",
      "messy.py:2:0: C0410: Multiple imports on one line (pandas, numpy) (multiple-imports)\n",
      "Exception on node <ImportFrom l.3 at 0x104cbe3c0> in file '/Users/shahbaz/Documents/GitHub/ProgrammingForAnalytics/lectures/110_python_py_files/messy.py'\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/imports.py\", line 846, in _get_imported_module\n",
      "    return importnode.do_import_module(modname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py\", line 146, in do_import_module\n",
      "    return mymodule.import_module(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py\", line 527, in import_module\n",
      "    return AstroidManager().ast_from_module_name(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py\", line 232, in ast_from_module_name\n",
      "    return self.ast_from_file(found_spec.location, modname, fallback=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py\", line 124, in ast_from_file\n",
      "    return AstroidBuilder(self).file_build(filepath, modname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py\", line 144, in file_build\n",
      "    module, builder = self._data_build(data, modname, path)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py\", line 204, in _data_build\n",
      "    module = builder.visit_module(node, modname, node_file, package)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py\", line 254, in visit_module\n",
      "    [self.visit(child, newnode) for child in node.body],\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py\", line 603, in visit\n",
      "    visit_method = getattr(self, visit_name)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py\", line 91, in walk\n",
      "    callback(astroid)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/imports.py\", line 541, in visit_importfrom\n",
      "    imported_module = self._get_imported_module(node, basename)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/imports.py\", line 871, in _get_imported_module\n",
      "    raise astroid.AstroidError from e\n",
      "astroid.exceptions.AstroidError\n",
      "messy.py:1:0: F0002: messy.py: Fatal error while checking 'messy.py'. Please open an issue in our bug tracker so we address this. There is a pre-filled template that you can use in '/Users/shahbaz/Library/Caches/pylint/pylint-crash-2025-06-30-20-12-10.txt'. (astroid-error)\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Your code has been rated at 0.00/10 (previous run: 0.00/10, +0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pylint messy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15bd1c7f-3daf-42db-aa55-97119a13e8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--- messy.py\t2025-04-17 01:12:17.215143+00:00\u001b[0m\n",
      "\u001b[1m+++ messy.py\t2025-07-01 01:22:20.017968+00:00\u001b[0m\n",
      "\u001b[36m@@ -1,44 +1,51 @@\u001b[0m\n",
      " # messy.py\n",
      "\u001b[31m-import pandas as pd,numpy as np\u001b[0m\n",
      "\u001b[31m-from typing import List,Dict,Any\u001b[0m\n",
      "\u001b[32m+import pandas as pd, numpy as np\u001b[0m\n",
      "\u001b[32m+from typing import List, Dict, Any\u001b[0m\n",
      " import matplotlib.pyplot as plt\n",
      " \n",
      "\u001b[32m+\u001b[0m\n",
      " class dataProcessor:\n",
      "\u001b[31m-    def __init__(self,input_file:str,    output_file:str='processed.csv'):\u001b[0m\n",
      "\u001b[31m-        self.input=input_file\u001b[0m\n",
      "\u001b[31m-        self.output_file=output_file\u001b[0m\n",
      "\u001b[31m-        self.data=None\u001b[0m\n",
      "\u001b[31m-    \u001b[0m\n",
      "\u001b[32m+    def __init__(self, input_file: str, output_file: str = \"processed.csv\"):\u001b[0m\n",
      "\u001b[32m+        self.input = input_file\u001b[0m\n",
      "\u001b[32m+        self.output_file = output_file\u001b[0m\n",
      "\u001b[32m+        self.data = None\u001b[0m\n",
      "\u001b[32m+\u001b[0m\n",
      "     def Load_data(self):\n",
      "         \"\"\"loads data from csv file\"\"\"\n",
      "\u001b[31m-        self.data=pd.read_csv(self.input)\u001b[0m\n",
      "\u001b[32m+        self.data = pd.read_csv(self.input)\u001b[0m\n",
      "         return self.data\n",
      "\u001b[31m-    \u001b[0m\n",
      "\u001b[31m-    def process(self,columns_to_process:List[str]=[],aggfunc:str='mean')->pd.DataFrame:\u001b[0m\n",
      "\u001b[31m-        if len(columns_to_process)==0: return self.data\u001b[0m\n",
      "\u001b[31m-        processed_data={}\u001b[0m\n",
      "\u001b[32m+\u001b[0m\n",
      "\u001b[32m+    def process(\u001b[0m\n",
      "\u001b[32m+        self, columns_to_process: List[str] = [], aggfunc: str = \"mean\"\u001b[0m\n",
      "\u001b[32m+    ) -> pd.DataFrame:\u001b[0m\n",
      "\u001b[32m+        if len(columns_to_process) == 0:\u001b[0m\n",
      "\u001b[32m+            return self.data\u001b[0m\n",
      "\u001b[32m+        processed_data = {}\u001b[0m\n",
      "         for col in columns_to_process:\n",
      "\u001b[31m-         if col in self.data.columns:\u001b[0m\n",
      "\u001b[31m-          processed_data[col]=getattr(self.data[col],aggfunc)()\u001b[0m\n",
      "\u001b[31m-         else:\u001b[0m\n",
      "\u001b[31m-            print(f\"Warning: Column {col} not found\")\u001b[0m\n",
      "\u001b[31m-        return pd.DataFrame(processed_data,index=[0])\u001b[0m\n",
      "\u001b[32m+            if col in self.data.columns:\u001b[0m\n",
      "\u001b[32m+                processed_data[col] = getattr(self.data[col], aggfunc)()\u001b[0m\n",
      "\u001b[32m+            else:\u001b[0m\n",
      "\u001b[32m+                print(f\"Warning: Column {col} not found\")\u001b[0m\n",
      "\u001b[32m+        return pd.DataFrame(processed_data, index=[0])\u001b[0m\n",
      " \n",
      "\u001b[31m-    def visualize_data(self,   column:str,   PlotType:str='bar'   )->None:\u001b[0m\n",
      "\u001b[31m-        if self.data is None:raise ValueError('No data loaded')\u001b[0m\n",
      "\u001b[31m-        plt.figure(figsize=(10,     5))\u001b[0m\n",
      "\u001b[31m-        if PlotType=='bar':\u001b[0m\n",
      "\u001b[31m-            self.data[column].value_counts().plot(kind='bar')\u001b[0m\n",
      "\u001b[31m-        elif     PlotType=='hist':\u001b[0m\n",
      "\u001b[32m+    def visualize_data(self, column: str, PlotType: str = \"bar\") -> None:\u001b[0m\n",
      "\u001b[32m+        if self.data is None:\u001b[0m\n",
      "\u001b[32m+            raise ValueError(\"No data loaded\")\u001b[0m\n",
      "\u001b[32m+        plt.figure(figsize=(10, 5))\u001b[0m\n",
      "\u001b[32m+        if PlotType == \"bar\":\u001b[0m\n",
      "\u001b[32m+            self.data[column].value_counts().plot(kind=\"bar\")\u001b[0m\n",
      "\u001b[32m+        elif PlotType == \"hist\":\u001b[0m\n",
      "             self.data[column].hist()\n",
      "\u001b[31m-        plt.title(f'Visualization of {column}')\u001b[0m\n",
      "\u001b[32m+        plt.title(f\"Visualization of {column}\")\u001b[0m\n",
      "         plt.show()\n",
      " \n",
      "\u001b[32m+\u001b[0m\n",
      " def main():\n",
      "\u001b[31m-    processor=dataProcessor('data.csv')\u001b[0m\n",
      "\u001b[32m+    processor = dataProcessor(\"data.csv\")\u001b[0m\n",
      "     df = processor.Load_data()\n",
      "\u001b[31m-    processed=processor.process(['age','salary'],aggfunc='mean')\u001b[0m\n",
      "\u001b[31m-    processor.visualize_data('age','hist')\u001b[0m\n",
      "\u001b[32m+    processed = processor.process([\"age\", \"salary\"], aggfunc=\"mean\")\u001b[0m\n",
      "\u001b[32m+    processor.visualize_data(\"age\", \"hist\")\u001b[0m\n",
      " \n",
      "\u001b[31m-if __name__=='__main__':\u001b[0m\n",
      "\u001b[32m+\u001b[0m\n",
      "\u001b[32m+if __name__ == \"__main__\":\u001b[0m\n",
      "     main()\n",
      "\u001b[1mwould reformat messy.py\u001b[0m\n",
      "\n",
      "\u001b[1mAll done! ‚ú® üç∞ ‚ú®\u001b[0m\n",
      "\u001b[34m\u001b[1m1 file \u001b[0m\u001b[1mwould be reformatted\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "!black messy.py --diff --color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e703b-3147-4245-9102-98c4f1401d73",
   "metadata": {},
   "source": [
    "NOTE: Exercises created with assistance from Claud AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d8e8d-2938-4b9b-9120-c0b3dfb24bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
