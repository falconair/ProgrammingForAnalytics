{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d775b5d-8fdf-449d-a4a7-5fcc913ceee0",
   "metadata": {},
   "source": [
    "# Dask cluster\n",
    "\n",
    "The Dask team desecribes themselves as a distributed Pandas library. Lucky for us, the distribute more than just pandas - they even have distributed machine learning libraries. Let's kick the tires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1b8da-b60b-47c7-bddb-9b72f66e4e1c",
   "metadata": {},
   "source": [
    "#### Create a docker image which has all necessary softawre installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80af6da-2c07-481b-a197-8de28c306152",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "FROM continuumio/miniconda3\n",
    "RUN apt update && apt install -y iputils-ping iproute2\n",
    "RUN pip install \"dask[complete]\"\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fab8cf-7037-40a2-90b5-90fb4085f157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!docker build -t test-dask-image ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7351c5-c559-4eec-b917-f02f57cc8594",
   "metadata": {},
   "source": [
    "#### Create a simulated network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c99504-b557-44cc-b49e-eeaa22426775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulated-cluster\n"
     ]
    }
   ],
   "source": [
    "!docker network rm simulated-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1384749d-d582-4296-861c-dc3c87c23b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85985a41b77ac26d1230cd3aea9bb569684319dfe120f4524acf7de6f15bd7ca\n"
     ]
    }
   ],
   "source": [
    "!docker network create simulated-cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c881e621-1c91-4cea-8334-ad196773d4f4",
   "metadata": {},
   "source": [
    "#### Start a docker container \n",
    "Scheduler at port 8786 and UI at port 8787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "526a50c3-9722-411e-b5f9-df21497acd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e49e35dece8298a97bbe3658450d1cb44f802cc452667b972ce31e687ca1c2a2\n"
     ]
    }
   ],
   "source": [
    "!docker run -dit --network simulated-cluster -p 8786:8786 -p 8787:8787 --name dask-scheduler test-dask-image dask scheduler --host 0.0.0.0 --dashboard-address 0.0.0.0:8787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1d8672-9f62-465e-b86c-5a2ac070bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 01:24:20,221 - distributed.scheduler - INFO - -----------------------------------------------\n",
      "2025-03-04 01:24:20,535 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "2025-03-04 01:24:20,554 - distributed.scheduler - INFO - State start\n",
      "2025-03-04 01:24:20,558 - distributed.scheduler - INFO - -----------------------------------------------\n",
      "2025-03-04 01:24:20,559 - distributed.scheduler - INFO -   Scheduler at:     tcp://172.18.0.2:8786\n",
      "2025-03-04 01:24:20,559 - distributed.scheduler - INFO -   dashboard at:  http://172.18.0.2:8787/status\n",
      "2025-03-04 01:24:20,559 - distributed.scheduler - INFO - Registering Worker plugin shuffle\n"
     ]
    }
   ],
   "source": [
    "!docker logs dask-scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e113977-44f5-4678-a1c3-17b2f292eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n",
      "    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n",
      "    inet 127.0.0.1/8 scope host lo\n",
      "       valid_lft forever preferred_lft forever\n",
      "    inet6 ::1/128 scope host \n",
      "       valid_lft forever preferred_lft forever\n",
      "238: eth0@if239: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n",
      "    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n",
      "    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0\n",
      "       valid_lft forever preferred_lft forever\n"
     ]
    }
   ],
   "source": [
    "!docker exec dask-scheduler ip addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d67c993-dc97-4ade-84fe-48b4041199f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEDULER_IP = \"172.18.0.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1682fbb-5387-443d-9902-1dcae46227ca",
   "metadata": {},
   "source": [
    "#### Start workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe9e95b4-f267-4065-9f1a-29ce9d50b46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8483cce7f3b7dc47b99246bf711d52ec6a7f03238ab56453ce5d1337b259f432\n",
      "1c0974bb7249ac53b5ad65d83aceb8c158301b7406c691f743be3a4e72c6ecfd\n",
      "272e8295f91a463211a46039f33fbea27eb6f7229cebcd10fe927f0cf1030219\n"
     ]
    }
   ],
   "source": [
    "!docker run -dit --network simulated-cluster --name dask-worker1 test-dask-image dask worker dask-scheduler:8786\n",
    "!docker run -dit --network simulated-cluster --name dask-worker2 test-dask-image dask worker dask-scheduler:8786\n",
    "!docker run -dit --network simulated-cluster --name dask-worker3 test-dask-image dask worker dask-scheduler:8786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb43cd93-c852-4f18-8cf4-c84065ba0e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 01:24:28,315 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.18.0.3:36955'\n",
      "2025-03-04 01:24:28,981 - distributed.worker - INFO -       Start worker at:     tcp://172.18.0.3:45925\n",
      "2025-03-04 01:24:28,981 - distributed.worker - INFO -          Listening to:     tcp://172.18.0.3:45925\n",
      "2025-03-04 01:24:28,981 - distributed.worker - INFO -          dashboard at:           172.18.0.3:41579\n",
      "2025-03-04 01:24:28,981 - distributed.worker - INFO - Waiting to connect to:  tcp://dask-scheduler:8786\n",
      "2025-03-04 01:24:28,981 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-03-04 01:24:28,981 - distributed.worker - INFO -               Threads:                         22\n",
      "2025-03-04 01:24:28,981 - distributed.worker - INFO -                Memory:                  15.35 GiB\n",
      "2025-03-04 01:24:28,981 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nsdbc8iz\n",
      "2025-03-04 01:24:28,981 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-03-04 01:24:29,829 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "2025-03-04 01:24:29,829 - distributed.worker - INFO -         Registered to:  tcp://dask-scheduler:8786\n",
      "2025-03-04 01:24:29,830 - distributed.worker - INFO - -------------------------------------------------\n",
      "2025-03-04 01:24:29,830 - distributed.core - INFO - Starting established connection to tcp://dask-scheduler:8786\n"
     ]
    }
   ],
   "source": [
    "!docker logs dask-worker1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba5a90-7eaa-46da-9e8a-553ead2f6b7b",
   "metadata": {},
   "source": [
    "### Now test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c06d72e2-ddb9-49e8-a3cd-4f1a790cabe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install \"dask[complete]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c70bd71-3bb2-4cb2-81ac-febc70aa471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahb\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\cupy\\_environment.py:217: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9698a8b0-cbcd-452c-87de-b65711a9a525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Timed out trying to connect to tcp://172.18.0.2:8786 after 30 s",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\utils.py:1910\u001b[0m, in \u001b[0;36mwait_for\u001b[1;34m(fut, timeout)\u001b[0m\n\u001b[0;32m   1909\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mtimeout(timeout):\n\u001b[1;32m-> 1910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\comm\\tcp.py:547\u001b[0m, in \u001b[0;36mBaseTCPConnector.connect\u001b[1;34m(self, address, deserialize, **connection_args)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 547\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m    548\u001b[0m         ip, port, max_buffer_size\u001b[38;5;241m=\u001b[39mMAX_BUFFER_SIZE, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    549\u001b[0m     )\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# Under certain circumstances tornado will have a closed connection with an\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# error and not raise a StreamClosedError.\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# This occurs with tornado 5.x and openssl 1.1+\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\tornado\\tcpclient.py:279\u001b[0m, in \u001b[0;36mTCPClient.connect\u001b[1;34m(self, host, port, af, ssl_options, max_buffer_size, source_ip, source_port, timeout)\u001b[0m\n\u001b[0;32m    270\u001b[0m connector \u001b[38;5;241m=\u001b[39m _Connector(\n\u001b[0;32m    271\u001b[0m     addrinfo,\n\u001b[0;32m    272\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m     ),\n\u001b[0;32m    278\u001b[0m )\n\u001b[1;32m--> 279\u001b[0m af, addr, stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connector\u001b[38;5;241m.\u001b[39mstart(connect_timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# TODO: For better performance we could cache the (af, addr)\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# information here and re-use it on subsequent connections to\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# the same host. (http://tools.ietf.org/html/rfc6555#section-4.2)\u001b[39;00m\n",
      "\u001b[1;31mCancelledError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\comm\\core.py:342\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(addr, timeout, deserialize, handshake_overrides, **connection_args)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 342\u001b[0m     comm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m wait_for(\n\u001b[0;32m    343\u001b[0m         connector\u001b[38;5;241m.\u001b[39mconnect(loc, deserialize\u001b[38;5;241m=\u001b[39mdeserialize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconnection_args),\n\u001b[0;32m    344\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(intermediate_cap, time_left()),\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\utils.py:1909\u001b[0m, in \u001b[0;36mwait_for\u001b[1;34m(fut, timeout)\u001b[0m\n\u001b[0;32m   1908\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for\u001b[39m(fut: Awaitable[T], timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m-> 1909\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mtimeout(timeout):\n\u001b[0;32m   1910\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\asyncio\\timeouts.py:115\u001b[0m, in \u001b[0;36mTimeout.__aexit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task\u001b[38;5;241m.\u001b[39muncancel() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cancelling \u001b[38;5;129;01mand\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;66;03m# Since there are no new cancel requests, we're\u001b[39;00m\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;66;03m# handling this.\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc_val\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01mis\u001b[39;00m _State\u001b[38;5;241m.\u001b[39mENTERED:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Connect to the Dask scheduler inside Docker\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m Client(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtcp://172.18.0.2:8786\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Use the actual scheduler IP\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Verify connection\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(client)\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\client.py:1230\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, address, loop, timeout, set_as_default, scheduler_file, security, asynchronous, name, heartbeat_interval, serializers, deserializers, extensions, direct_to_workers, connection_limit, **kwargs)\u001b[0m\n\u001b[0;32m   1227\u001b[0m preload_argv \u001b[38;5;241m=\u001b[39m dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistributed.client.preload-argv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreloads \u001b[38;5;241m=\u001b[39m preloading\u001b[38;5;241m.\u001b[39mprocess_preloads(\u001b[38;5;28mself\u001b[39m, preload, preload_argv)\n\u001b[1;32m-> 1230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1231\u001b[0m Client\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecreate_tasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReplayTaskClient\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\client.py:1432\u001b[0m, in \u001b[0;36mClient.start\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1432\u001b[0m     sync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\utils.py:439\u001b[0m, in \u001b[0;36msync\u001b[1;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m         wait(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\utils.py:413\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m    411\u001b[0m         awaitable \u001b[38;5;241m=\u001b[39m wait_for(awaitable, timeout)\n\u001b[0;32m    412\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(awaitable)\n\u001b[1;32m--> 413\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m    415\u001b[0m     error \u001b[38;5;241m=\u001b[39m exception\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\tornado\\gen.py:766\u001b[0m, in \u001b[0;36mRunner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m         value \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    768\u001b[0m         \u001b[38;5;66;03m# Save the exception for later. It's important that\u001b[39;00m\n\u001b[0;32m    769\u001b[0m         \u001b[38;5;66;03m# gen.throw() not be called inside this try/except block\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;66;03m# because that makes sys.exc_info behave unexpectedly.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m         exc: Optional[\u001b[38;5;167;01mException\u001b[39;00m] \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\client.py:1511\u001b[0m, in \u001b[0;36mClient._start\u001b[1;34m(self, timeout, **kwargs)\u001b[0m\n\u001b[0;32m   1508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler_comm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_connected(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close()\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\client.py:1579\u001b[0m, in \u001b[0;36mClient._ensure_connected\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connecting_to_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1578\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1579\u001b[0m     comm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connect(\n\u001b[0;32m   1580\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39maddress, timeout\u001b[38;5;241m=\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_args\n\u001b[0;32m   1581\u001b[0m     )\n\u001b[0;32m   1582\u001b[0m     comm\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient->Scheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\mleng_env\\Lib\\site-packages\\distributed\\comm\\core.py:368\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(addr, timeout, deserialize, handshake_overrides, **connection_args)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(backoff)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    369\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out trying to connect to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    370\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mactive_exception\u001b[39;00m\n\u001b[0;32m    372\u001b[0m local_info \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomm\u001b[38;5;241m.\u001b[39mhandshake_info(),\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(handshake_overrides \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[0;32m    375\u001b[0m }\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mwrite(local_info)\n",
      "\u001b[1;31mOSError\u001b[0m: Timed out trying to connect to tcp://172.18.0.2:8786 after 30 s"
     ]
    }
   ],
   "source": [
    "# Connect to the Dask scheduler inside Docker\n",
    "client = Client(\"tcp://172.18.0.2:8786\")  # Use the actual scheduler IP\n",
    "\n",
    "# Verify connection\n",
    "print(client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c36ff-df2c-42d8-b260-ed19fda3f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some distributed computation\n",
    "arr = da.random.random((10000, 10000), chunks=(1000, 1000))\n",
    "result = arr.mean().compute()  # Executes on the Dask workers\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246d44c-b311-4b3b-af4d-6523168e7fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-mleng_env]",
   "language": "python",
   "name": "conda-env-conda-mleng_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
